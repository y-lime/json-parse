# GitHub Copilot エージェントモードの内部構造まとめ

---

## 1. エージェントモードの概要

GitHub Copilot のエージェントモード（Copilot Chat や Copilot Workspace など）は、従来のコード補完を超え、ユーザーの自然言語指示に応じてタスク分解・計画・実行・検証まで自律的に行う AI アシスタント機能です。

---

## 2. 内部動作の流れ

1. **プロンプト受け取り**
   - ユーザーが自然言語で指示を入力
2. **コンテキスト収集**
   - VS Code 拡張機能がワークスペースやエディタの情報を収集
3. **タスク分解・計画**
   - LLM（大規模言語モデル）が指示を細かいタスクに分解し、実行順を決定
4. **コード生成・編集**
   - 必要なコードや設定ファイルを生成・編集
5. **実行・検証**
   - テストやビルド、コマンド実行を自動化し、結果を取得
6. **フィードバックと繰り返し**
   - 実行結果やユーザーの追加指示に応じて再計画・修正
7. **結果提示**
   - 変更内容や成果物をユーザーに提示

---

## 3. コンテキスト収集の仕組みと工夫

### 3.1 収集対象

- **VS Code 拡張機能**が、
  - アクティブなファイル・選択範囲・カーソル位置
  - ワークスペース内のファイル構成
  - 設定ファイルや git 情報
  - 過去の会話履歴
    などを API（例：`vscode.workspace.findFiles`, `vscode.window.activeTextEditor`）で収集。
- 収集した情報を LLM にプロンプトとして送信。
- LLM は受け取ったコンテキストをもとに推論・生成を行う。

### 3.2 実装パターン

- ファイル検索は`findFiles`で glob パターンを活用。
- ファイルの有無チェックは`findFiles`の戻り値で判定。
- ファイル内容取得は`openTextDocument`で全文取得し、必要部分のみ抽出。
- 抽出範囲は LLM のリクエスト内容をキーワード・正規表現・パーサー等で解析。
- トークン制限回避のため、全文送信は避け、要約や抜粋を優先。
- LLM が「追加情報が必要」と判断した場合、拡張機能が再度該当部分を取得し送信。
- 追加情報リクエストの許可は system prompt で明示するのがベストプラクティス。

---

## 4. タスク分解・計画の高度化

- LLM がユーザー指示を解析し、必要な作業を小さなタスクに分割
- タスクを実行順に並べて計画
- サブタスクごとに実行・検証し、状況に応じて再計画
- 例：認証機能追加 → パッケージ導入 → 設定 → 画面作成 → テスト → 動作確認

### 4.1 タスク分解プロンプト設計例

```
あなたはソフトウェア開発プロジェクトのAIアシスタントです。
以下のユーザー指示を達成するために、必要な作業を複数の具体的なタスクに分解し、実行順にリストアップしてください。
【プロジェクトの概要】
- 使用言語: TypeScript
- フレームワーク: Next.js
- 主要なファイル: ...（要約や抜粋）
【ユーザーの指示】
「このプロジェクトにユーザー認証機能を追加して」
【出力フォーマット】
1. タスク1
2. タスク2
...
```

- system prompt で「情報が不足している場合は追加情報をリクエストしてよい」と明示。
- LLM の推論能力で「何が必要か」を自律的に判断させる設計。

---

## 5. 実行・検証サイクルの自律化と安全設計

- LLM が「どのコマンドを実行すべきか」判断
- VS Code 拡張機能がターミナルやタスク API でコマンドを実行
- 実行結果（標準出力・エラー）を取得し、LLM にフィードバック
- エラー時は LLM が修正案を生成し、再度実行 → 検証のサイクルを自動化
- 危険な操作はユーザーに確認ダイアログ（`vscode.window.showWarningMessage`等）で許可を求める
- コマンド実行前の確認は`showWarningMessage`の modal オプションで実装。
- 実行結果の解析・修正案生成も LLM が担い、AI 主導で「修正 → 再実行 → 検証」を繰り返す。
- テストやビルドの自動化はプロジェクト構成や言語・ツールを LLM が推論し、最適なコマンドを選択。
- セキュリティ上、ユーザーの明示的な許可なしに危険な操作は行わない。

---

## 6. 外部ソース検索と連携

- GitHub リポジトリや Web ページ、パッケージレジストリなど外部 API を活用し、情報取得・要約・分析が可能
- Copilot 拡張機能やバックエンドが外部 API や Web リクエストで情報を取得し、LLM に渡す
- プライベートや認証が必要なリソースにはアクセス不可
- 取得した情報は要約・抜粋して LLM に渡し、トークン制限を回避

---

## 7. ファイル内容の抽出・要約の多様な手法

- トークン制限のため、ファイル全文は送らず、必要な部分だけを抽出・要約
- LLM のリクエスト内容を拡張機能が解析し、該当箇所（クラス・関数・セクション等）を正規表現・パーサー・キーワード検索等で抜粋
- 必要に応じて LLM に「抽出条件を正規表現で返す」よう指示する場合もある
- 構文解析（パーサーや AST）、キーワード・インデント・ブロック解析、セクション分割、LLM 自身による抜粋、事前インデックス活用など多様な手法を組み合わせ
- ファイル全体を LLM に送るのは小規模な場合のみ
- 事前インデックスやシンボルテーブルを活用し、該当箇所を高速抽出

---

## 8. 事前インデックス（pre-indexing）の構造と運用

- プロジェクト全体をパースし、クラス・関数・設定・リソース等の位置・構造情報をデータベースやメモリ上に保持
- 例：クラス名・関数名・定義位置・階層・参照関係・設定セクション・テスト情報など
- インデックスには以下の情報が含まれる：
  - ファイルパス・種別・サイズ・更新日時
  - クラス・関数・変数・定数・シンボル名と定義位置
  - 構造・階層・継承・ネスト情報
  - 参照・依存関係・呼び出し元/先
  - 設定ファイルのキー・セクション・階層
  - テスト・ビルド・エントリーポイント情報
  - コメント・ドキュメント・TODO タグ
- インデックスはファイル更新時に差分更新し、常に最新状態を維持
- 言語ごとのパーサーや LSP、独自スキャナでインデックスを生成
- インデックスは JSON や SQLite、インメモリ DB 等で管理
- 依存関係や参照関係の解析も容易

---

## 9. LLM とのやりとりの設計思想

- API 自体は Chat 形式だが、プロンプトの構造が高度（system prompt で役割・方針、user prompt で具体指示）
- system prompt で「情報が足りなければ追加リクエストしてよい」「自律的に判断してよい」と明示
- LLM が「何が必要か」を自律的に判断し、必要なら追加情報をリクエスト
- 拡張機能は LLM の自然言語リクエストをパースし、該当ファイル・箇所を特定
- LLM に正規表現で抽出条件を返させる設計も採用例あり
- 追加情報リクエストの仕組みは system prompt に組み込むのがベストプラクティス

---

## 10. VS Code 拡張機能と Copilot の役割分担

- **VS Code 拡張機能**
  - コンテキスト収集、ファイル操作、コマンド実行、ユーザーへの UI 表示、インデックス管理
- **LLM（Copilot 本体）**
  - 意図理解、タスク分解・計画、コード生成、実行結果の解析、追加情報リクエスト、抽出条件の生成

---

## 11. 参考 API 一覧

- `vscode.workspace.findFiles()`：ファイル検索
- `vscode.workspace.openTextDocument()`：ファイル内容取得
- `vscode.window.activeTextEditor`：エディタ情報取得
- `vscode.window.showInformationMessage()`：ダイアログ表示
- `vscode.window.createTerminal()`：ターミナル実行
- `vscode.workspace.getConfiguration()`：設定取得
- `vscode.commands.onDidExecuteCommand`：コマンド履歴取得

---

## 12. Copilot の限界と今後の発展

- LLM のトークン制限や推論精度の限界
- 構文解析やインデックスの精度・言語対応範囲
- セキュリティ・プライバシー配慮（外部送信範囲の制御）
- ユーザー体験向上のための UI/UX 改善
- 今後はより高度なインデックス・LLM 連携、リアルタイムな双方向対話、プロジェクト横断的な知識活用などが期待される

---

## 13. まとめ

GitHub Copilot のエージェントモードは、

- VS Code 拡張機能による高度なコンテキスト収集・操作・インデックス化
- LLM による意図理解・タスク分解・自律的な実行・検証・追加情報リクエスト
- ファイル内容の効率的な抽出・要約と事前インデックス化
- 外部ソース検索やユーザー確認などの安全設計
- 柔軟なプロンプト設計と AI 主導のタスク遂行

これらを組み合わせることで、自然言語による柔軟かつ強力な開発支援を実現している。
